### Experiments

Remember to experiment with and without PCA

1. Decision tree algorithms without PCA
Accuracy scores were perfect suggesting overfitting despite pruning.
2. Decision Tree algorithm with PCA
Score looks more realistic, reduced to 3 PCA's
    Accuracy: 0.9485815602836879
    Classification Report:
                precision    recall  f1-score   support

            1       0.96      0.97      0.97       828
            2       0.92      0.88      0.90       300

        accuracy                           0.95      1128
    macro avg       0.94      0.93      0.93      1128
    weighted avg       0.95      0.95      0.95      1128

--- 828 vs 300, class imbalance, suggests a need for difference approach
potential justification for using AUC and ROC for analysis. 
3. AUC: 0.9267149758454105 suggests that the model has a strong ability to distinguish 
betwen the positive and negative classes.
4. Initial run of logistic regression suggests that it is only predicting one class. Possibly due to
class imbalance
5. SVM has similar issues